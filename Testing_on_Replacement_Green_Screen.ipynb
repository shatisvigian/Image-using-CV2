{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Testing on Replacement Green Screen.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMLM3jglKO27f8KAXEqfM5i",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shatisvigian/Image-using-CV2/blob/main/Testing_on_Replacement_Green_Screen.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "def cv2_imshow(a, **kwargs):\n",
        "    a = a.clip(0, 255).astype('uint8')\n",
        "    # cv2 stores colors as BGR; convert to RGB\n",
        "    if a.ndim == 3:\n",
        "        if a.shape[2] == 4:\n",
        "            a = cv2.cvtColor(a, cv2.COLOR_BGRA2RGBA)\n",
        "        else:\n",
        "            a = cv2.cvtColor(a, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    return plt.imshow(a, **kwargs)"
      ],
      "metadata": {
        "id": "PfxF21ry8Jgz"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab.patches import cv2_imshow\n",
        "cv2_imshow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a1pFwuDnjIe1",
        "outputId": "521e6950-efbf-440c-d2da-081aa4effe5c"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function google.colab.patches.cv2_imshow>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "id": "-0Nw4HaRMmOY",
        "outputId": "cdc54648-1b24-4059-c2fc-08b2bf68daf9"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "error",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-1349bf919458>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvideo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m640\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m480\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m640\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m480\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mu_green\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m104\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m153\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m70\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31merror\u001b[0m: OpenCV(4.1.2) /io/opencv/modules/imgproc/src/resize.cpp:3720: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "import numpy as np \n",
        "import matplotlib.pyplot as plt\n",
        "# import cv2\n",
        "video = cv2.VideoCapture(\"/content/video tutorial.mp4\")\n",
        "image = cv2.imread(\"/content/WhatsApp Image 2022-01-27 at 12.24.12 PM.jpeg\")\n",
        "while True:\n",
        "    ret, frame = video.read()\n",
        "    frame = cv2.resize(frame, (640, 480))\n",
        "    image = cv2.resize(frame, (640, 480))\n",
        "    u_green = np.array([104, 153, 70])\n",
        "    l_green = np.array([30, 30, 0])\n",
        "    mask = cv2.inRange(frame, l_green, u_green)\n",
        "    res = cv2.bitwise_and(frame, frame, mask = mask)\n",
        "    f = frame - res\n",
        "    f = np.where(f == 0, image, f)\n",
        "    cv2.bitwise_and(frame, frame, mask = mask)\n",
        "    f = frame - res\n",
        "    f = np.where(f == 0, image, f)\n",
        "    plt.figure(figsize=(10,18))\n",
        "    plt.figure(figsize=(10,18))\n",
        "    if cv2.waitKey(25) == 27:\n",
        "      break\n",
        "video.release()\n",
        "cv2.destroyAllWindows()\n",
        "\n"
      ]
    }
  ]
}